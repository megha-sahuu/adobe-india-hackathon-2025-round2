# Approach Explanation: Persona-Driven Document Intelligence

## Overview
This solution is designed to extract and prioritize the most relevant sections from a collection of documents (PDFs) based on a specific persona and their job-to-be-done. The approach is generic and can handle diverse document types, personas, and tasks.

## Methodology

### 1. PDF Parsing
We use `pdfplumber`, a lightweight and efficient PDF parsing library, to extract text from each page of the provided documents. This ensures compatibility with a wide range of PDF layouts and keeps resource usage low.

### 2. Section Segmentation
Sections are identified using a combination of heuristics and regular expressions. Common section title patterns (e.g., bold, all-caps, numbered headings) are detected to segment the document into logical sections, each associated with a page number and title.

### 3. Persona & Job Understanding
The persona and job-to-be-done are parsed to extract key focus areas. We use simple keyword extraction (with NLTK) and custom rules to identify the most important terms and concepts relevant to the persona's task.

### 4. Relevance Scoring
Each section is scored for relevance using TF-IDF vectorization and cosine similarity (via scikit-learn) between the section text and the combined persona/job keywords. This allows us to rank sections by their importance to the user's needs.

### 5. Ranking & Extraction
The top-ranked sections are selected, and their titles, page numbers, and document names are recorded. For each, a refined summary is generated by extracting the most relevant sentences or sub-sections.

### 6. Output Formatting
The results are structured in a JSON format matching the challenge requirements, including metadata, extracted sections, and sub-section analysis.

## Constraints Handling
- All libraries and models are CPU-friendly and under 1GB.
- No internet access is required at runtime.
- Processing is optimized to complete within 60 seconds for 3-5 documents.

## Generalization
The pipeline is designed to be domain-agnostic, relying on text similarity and keyword extraction rather than hardcoded rules, ensuring it works for research, business, educational, and other document types. 